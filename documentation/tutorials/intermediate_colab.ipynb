{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yo62ffS5TF5"
      },
      "source": [
        "# Intermediate Colab for TensorFlow Decision Forests\n",
        "\n",
        "Welcome to the **Intermediate Colab** for **TensorFlow Decision Forests** (**TF-DF**) ðŸ˜€.\n",
        "In this colab, you will learn about some more advanced capabilities of **TF-DF**, including how to deal with natural language features.\n",
        "\n",
        "This colab assumes you are familiar with the concepts presented the [Beginner colab](beginner_colab.ipynb), notably about the installation about TF-DF.\n",
        "\n",
        "In this colab, we will:\n",
        "\n",
        "1. Train a Random Forest that consumes text features natively as categorical sets.\n",
        "\n",
        "1. Train a Random Forest that consumes text features using a [TensorFlow Hub](https://www.tensorflow.org/hub) module. In this setting (transfer learning), the module is already pre-trained on a large text corpus.\n",
        "\n",
        "1. Train a Gradient Boosted Decision Trees (GBDT) and a Neural Network together. The GBDT will consume the output of the Neural Network.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZiInVYfffAb"
      },
      "outputs": [],
      "source": [
        "# Install TensorFlow Dececision Forests\n",
        "!pip install tensorflow_decision_forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EFndCFdoJM5"
      },
      "source": [
        "Install [Wurlitzer](https://pypi.org/project/wurlitzer/). It can be used to show\n",
        "the detailed training logs. This is only needed in colabs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L06XWRdSoLj5"
      },
      "outputs": [],
      "source": [
        "!pip install wurlitzer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzskapxq7gdo"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "executionInfo": {
          "elapsed": 126,
          "status": "ok",
          "timestamp": 1619771252593,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "RsCV2oAS7gC_"
      },
      "outputs": [],
      "source": [
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import math\n",
        "\n",
        "# copybara:strip_begin\n",
        "from colabtools.googlelog import CaptureLog as sys_pipes\n",
        "# copybara:strip_end_and_replace_begin\n",
        "# from wurlitzer import sys_pipes\n",
        "# copybara:replace_end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_D4Ft4o65XT"
      },
      "source": [
        "## Train a Random Forest on raw NLP features using the Categorical Set splitter.\n",
        "\n",
        "TF-DF can consume [categorical-set](https://arxiv.org/pdf/2009.09991.pdf) features natively. Categorical-sets represent text features as bags of words (or n-grams).\n",
        "\n",
        "For example: `\"The little blue dog\" ` â†’ `{\"the\", \"little\", \"blue\", \"dog\"}`\n",
        "\n",
        "In this example, we will train a Random Forest on the [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/index.html) (SST) dataset. The objective of this dataset is to classify sentences as carrying a *positive* or *negative* sentiment. We will use the binary classification version of the dataset curated in [TensorFlow Datasets](https://www.tensorflow.org/datasets/catalog/glue#gluesst2).\n",
        "\n",
        "**Note:** Categorical-set features can be expensive to train. In this colab, we will train a small Random Forest with 20 trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "executionInfo": {
          "elapsed": 3890,
          "status": "ok",
          "timestamp": 1619771256487,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "uVN-j0E4Q1T3",
        "outputId": "850c0951-86a3-4b3f-c81b-3a13fddc3b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'idx': 163, 'label': -1, 'sentence': b'not even the hanson brothers can save it'}\n",
            "{'idx': 131, 'label': -1, 'sentence': b'strong setup and ambitious goals fade as the film descends into unsophisticated scare tactics and b-film thuggery .'}\n",
            "{'idx': 1579, 'label': -1, 'sentence': b'too timid to bring a sense of closure to an ugly chapter of the twentieth century .'}\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "import tensorflow_datasets as tfds\n",
        "all_ds = tfds.load(\"glue/sst2\")\n",
        "\n",
        "# Display the first 3 examples of the test fold.\n",
        "for example in all_ds[\"test\"].take(3):\n",
        "  print({attr_name: attr_tensor.numpy() for attr_name, attr_tensor in example.items()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHiQUWE2XDYN"
      },
      "source": [
        "The dataset is modified as follows:\n",
        "\n",
        "1. The raw labels are integers in {-1, 1}, but the learning algorithm expects positive integer labels e.g. {0, 1}. Therefore, the labels are transformed as follows: `new_labels = (original_labels + 1) / 2`.\n",
        "1. A batch-size of 64 is applied to make reading the dataset more efficient.\n",
        "1. The `sentence` attribute needs to be tokenized, i.e. `\"hello world\" -\u003e [\"hello\", \"world\"]`.\n",
        "\n",
        "\n",
        "**Note:** We don't use the `test` split of the dataset as it does not have labels. If `test` split had labels, we would have concatenated the `validation` fold into the `train` one (e.g. `all_ds[\"train\"].concatenate(all_ds[\"validation\"])`).\n",
        "\n",
        "**Details:** Some decision forest learning algorithms do not need a validation dataset (e.g. Random Forests) while others do (e.g. Gradient Boosted Trees in some cases). Since each learning algorithm under TF-DF can use validation data differently, TF-DF handles train/validation splits internally. As a result, when you have a training and validation sets, they can always be concatenated as input to the learning algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "executionInfo": {
          "elapsed": 159,
          "status": "ok",
          "timestamp": 1619771256692,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "yqYDKTKdSPYw"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(example):\n",
        "  label = (example[\"label\"] + 1) // 2\n",
        "  return {\"sentence\" : tf.strings.split(example[\"sentence\"])}, label\n",
        "\n",
        "train_ds = all_ds[\"train\"].batch(64).map(prepare_dataset)\n",
        "test_ds = all_ds[\"validation\"].batch(64).map(prepare_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYkIjROI9w43"
      },
      "source": [
        "Finaly, we train and evaluate the model as usual. TF-DF  automatically detects multi-valued categorical features as categorical-set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "height": 300
        },
        "executionInfo": {
          "elapsed": 157659,
          "status": "ok",
          "timestamp": 1619771414353,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "mpxTtYo39wYZ",
        "outputId": "cf4e1ef6-2890-412e-92f4-8bf2461bc458"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "window[\"eb3d50dc-a98d-11eb-8ea0-1ca0b880083b\"] = colab.output.setOutputHeight(\"300px\", false, {\"interactive\": true});\n",
              "//# sourceURL=js_8066157094"
            ],
            "text/plain": [
              "\u003cIPython.core.display.Javascript at 0x7f53b017ee48\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I0430 10:27:36.787370 1237263 api.py:447] Collect training examples.\n",
            "Features: {'sentence': tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64))}\n",
            "Label: Tensor(\"data_2:0\", shape=(None,), dtype=int64)\n",
            "I0430 10:27:36.812072 1237263 api.py:447] Normalized features: {'sentence': SemanticTensor(semantic=\u003cSemantic.CATEGORICAL_SET: 4\u003e, tensor=tf.RaggedTensor(values=Tensor(\"data:0\", shape=(None,), dtype=string), row_splits=Tensor(\"data_1:0\", shape=(None,), dtype=int64)))}\n",
            "1053/1053 [==============================] - 4s 2ms/step\n",
            "I0430 10:27:40.972855 1237263 kernel.cc:712] Start Yggdrasil model training\n",
            "I0430 10:27:40.972951 1237263 kernel.cc:713] Collect training examples\n",
            "I0430 10:27:40.972984 1237263 kernel.cc:374] Number of batches: 1053\n",
            "I0430 10:27:40.973006 1237263 kernel.cc:375] Number of examples: 67349\n",
            "I0430 10:27:41.010633 1237263 data_spec_inference.cc:271] 12816 item(s) have been pruned (i.e. they are considered out of dictionary) for the column sentence (2000 item(s) left) because min_value_count=5 and max_number_of_unique_values=2000\n",
            "I0430 10:27:41.047999 1237263 kernel.cc:735] Dataset:\n",
            "Number of records: 67349\n",
            "Number of columns: 2\n",
            "\n",
            "Number of columns by type:\n",
            "\tCATEGORICAL_SET: 1 (50%)\n",
            "\tCATEGORICAL: 1 (50%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "CATEGORICAL_SET: 1 (50%)\n",
            "\t0: \"sentence\" CATEGORICAL_SET has-dict vocab-size:2001 num-oods:12816 (19.0292%) most-frequent:\"the\" 27205 (40.3941%)\n",
            "\n",
            "CATEGORICAL: 1 (50%)\n",
            "\t1: \"__LABEL\" CATEGORICAL integerized vocab-size:3 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "I0430 10:27:41.048450 1237263 kernel.cc:738] Configure learner\n",
            "I0430 10:27:41.048554 1237263 kernel.cc:763] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"sentence\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 30\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "I0430 10:27:41.048619 1237263 kernel.cc:766] Deployment config:\n",
            "I0430 10:27:41.048630 1237263 kernel.cc:788] Train model\n",
            "I0430 10:27:41.048886 1237263 random_forest.cc:290] Training random forest on 67349 example(s) and 1 feature(s).\n",
            "I0430 10:28:09.125597 1272685 random_forest.cc:559] Training of tree  1/30 (tree index:4) done accuracy:0.759673 logloss:8.66225\n",
            "I0430 10:28:37.311940 1272685 random_forest.cc:559] Training of tree  7/30 (tree index:6) done accuracy:0.780605 logloss:5.63189\n",
            "I0430 10:28:44.402194 1238311 cluster_costs.cc:383] int ipc::pubsub2::ClusterCosts::GetClusterDistance(const std::string \u0026, const std::string \u0026) const unable to get distance between \"\" () and \"vu\" (vu)\n",
            "I0430 10:29:05.967428 1272681 random_forest.cc:559] Training of tree  13/30 (tree index:13) done accuracy:0.798598 logloss:3.13366\n",
            "I0430 10:29:31.995235 1272681 random_forest.cc:559] Training of tree  19/30 (tree index:18) done accuracy:0.808322 logloss:2.67957\n",
            "I0430 10:29:45.103195 1272684 random_forest.cc:559] Training of tree  24/30 (tree index:23) done accuracy:0.808743 logloss:2.52096\n",
            "I0430 10:30:01.200729 1272681 random_forest.cc:559] Training of tree  25/30 (tree index:24) done accuracy:0.808579 logloss:2.49776\n",
            "I0430 10:30:11.785544 1272686 random_forest.cc:559] Training of tree  29/30 (tree index:27) done accuracy:0.810123 logloss:2.43965\n",
            "I0430 10:30:12.236276 1272684 random_forest.cc:559] Training of tree  30/30 (tree index:29) done accuracy:0.809886 logloss:2.42075\n",
            "I0430 10:30:12.236466 1237263 random_forest.cc:626] Final OOB metrics: accuracy:0.809886 logloss:2.42075\n",
            "I0430 10:30:12.555733 1237263 kernel.cc:794] Export model in log directory: /tmp/tmp4os6m5jo\n",
            "I0430 10:30:12.658104 1237263 kernel.cc:802] Save model in resources\n",
            "I0430 10:30:12.679619 1237263 kernel.cc:919] Loading model from path\n",
            "I0430 10:30:12.716300 1237263 decision_forest.cc:585] Model loaded with 30 root(s), 41978 node(s), and 1 input feature(s).\n",
            "I0430 10:30:12.716647 1237263 abstract_model.cc:861] Engine \"RandomForestGeneric\" built\n",
            "I0430 10:30:12.716667 1237263 kernel.cc:787] Use fast generic engine\n"
          ]
        }
      ],
      "source": [
        "%output_height 300px\n",
        "\n",
        "# Specify the model.\n",
        "model_1 = tfdf.keras.RandomForestModel(num_trees=30)\n",
        "\n",
        "# Optionally, add evaluation metrics.\n",
        "model_1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model.\n",
        "with sys_pipes():\n",
        "  model_1.fit(x=train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9FMFGzwiHCt"
      },
      "source": [
        "In the previous logs, note that `sentence` is a `CATEGORICAL_SET` feature.\n",
        "\n",
        "The model is evaluated as usual:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "executionInfo": {
          "elapsed": 1966,
          "status": "ok",
          "timestamp": 1619771416355,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "cpf-wHl094S1",
        "outputId": "354b3e6a-657e-449e-aff1-193b4c357dbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.7603\n",
            "BinaryCrossentropyloss: 0.0\n",
            "Accuracy: 0.7603210806846619\n"
          ]
        }
      ],
      "source": [
        "evaluation = model_1.evaluate(test_ds)\n",
        "\n",
        "print(f\"BinaryCrossentropyloss: {evaluation[0]}\")\n",
        "print(f\"Accuracy: {evaluation[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YliBX4GtjncQ"
      },
      "source": [
        "The training logs looks are follow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "height": 279
        },
        "executionInfo": {
          "elapsed": 218,
          "status": "ok",
          "timestamp": 1619771416579,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "OnTTtBNmjpo7",
        "outputId": "fa3f4ce7-af0a-41fe-f9b2-3b5e0319cfc8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "\u003cFigure size 600x400 with 1 Axes\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "logs = model_1.make_inspector().training_logs()\n",
        "plt.plot([log.num_trees for log in logs], [log.evaluation.accuracy for log in logs])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Out-of-bag accuracy\")\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4qJ0ig3kgic"
      },
      "source": [
        "More trees would probably be beneficial (I am sure of it because I tried :p)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iil_oyOhCNx6"
      },
      "source": [
        "## Train a Random Forest able to consume NLP features using a pre-trained TensorFlow Hub module\n",
        "\n",
        "In the previous example, we trained a Random Forest using raw text features. In the next example, we will use a pre-trained TF-Hub embedding to convert text features into a dense embedding, and then train a Random Forest on top of it. In this situation, the Random Forest will only \"see\" the numerical output of the embedding (i.e. it will not see the raw text). \n",
        "\n",
        "In this experiment,  will use the [Universal-Sentence-Encoder](https://tfhub.dev/google/universal-sentence-encoder/4). Different pre-trained embeddings might be suited for different types of text (e.g. different language, different task) but also for other type of structured features (e.g. images).\n",
        "\n",
        "**Note:** This embedding is large (1GB) and therefore the final model will be slow to run (compared to classical decision tree inference).\n",
        "\n",
        "The embedding module can be applied in one of two places:\n",
        "\n",
        "1. During the dataset preparation.\n",
        "2. In the pre-processing stage of the model.\n",
        "\n",
        "The second option is often preferable: Packaging the embedding in the model makes the model easier to use (and harder to misuse :) ).\n",
        "\n",
        "But first, let's install TF-Hub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "executionInfo": {
          "elapsed": 979,
          "status": "ok",
          "timestamp": 1619771417937,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "QfYGXim_DskC",
        "outputId": "1f368dfd-2873-467f-d0c1-64f9b2284934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/google/home/gbm/.local/lib/python3.9/site-packages (0.12.0)\n",
            "Requirement already satisfied: protobuf\u003e=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-hub) (3.15.7)\n",
            "Requirement already satisfied: numpy\u003e=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-hub) (1.19.5)\n",
            "Requirement already satisfied: six\u003e=1.9 in /usr/local/lib/python3.9/dist-packages (from protobuf\u003e=3.8.0-\u003etensorflow-hub) (1.15.0)\n",
            "WARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
            "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNSEhJgjEXww"
      },
      "source": [
        "Unlike before, we don't need to tokenize the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "executionInfo": {
          "elapsed": 111,
          "status": "ok",
          "timestamp": 1619771418056,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "pS5SYqoScbOc"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(example):\n",
        "  label = (example[\"label\"] + 1) // 2\n",
        "  return {\"sentence\" : example[\"sentence\"]}, label\n",
        "\n",
        "train_ds = all_ds[\"train\"].batch(64).map(prepare_dataset)\n",
        "test_ds = all_ds[\"validation\"].batch(64).map(prepare_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "height": 300
        },
        "executionInfo": {
          "elapsed": 74110,
          "status": "ok",
          "timestamp": 1619771492174,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "zHEsd8q_ESpC",
        "outputId": "23a78ece-486b-478a-88ec-1d751deb94c5"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "window[\"4b6e0e3a-a98e-11eb-b6bd-1ca0b880083b\"] = colab.output.setOutputHeight(\"300px\", false, {\"interactive\": true});\n",
              "//# sourceURL=js_86fca620dc"
            ],
            "text/plain": [
              "\u003cIPython.core.display.Javascript at 0x7f53b5564c18\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I0430 10:30:20.331904 1237263 api.py:447] Collect training examples.\n",
            "Features: {'sentence': \u003ctf.Tensor 'data:0' shape=(None,) dtype=string\u003e}\n",
            "Label: Tensor(\"data_1:0\", shape=(None,), dtype=int64)\n",
            "I0430 10:30:20.388400 1237263 api.py:447] Applying preprocessing on inputs. Result: {'embedded_sentence': \u003ctf.Tensor 'model_2/keras_layer_1/StatefulPartitionedCall:0' shape=(None, 512) dtype=float32\u003e}\n",
            "I0430 10:30:20.911289 1237263 api.py:447] Normalized features: {'embedded_sentence.0': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.1': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.2': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.3': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.4': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.5': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.6': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.7': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.8': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_8:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.9': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_9:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.10': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_10:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.11': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_11:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.12': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_12:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.13': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_13:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.14': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_14:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.15': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_15:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.16': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_16:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.17': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_17:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.18': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_18:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.19': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_19:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.20': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_20:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.21': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_21:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.22': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_22:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.23': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_23:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.24': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_24:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.25': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_25:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.26': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_26:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.27': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_27:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.28': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_28:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.29': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_29:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.30': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_30:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.31': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_31:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.32': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_32:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.33': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_33:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.34': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_34:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.35': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_35:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.36': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_36:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.37': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_37:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.38': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_38:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.39': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_39:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.40': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_40:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.41': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_41:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.42': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_42:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.43': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_43:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.44': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_44:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.45': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_45:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.46': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_46:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.47': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_47:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.48': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_48:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.49': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_49:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.50': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_50:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.51': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_51:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.52': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_52:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.53': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_53:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.54': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_54:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.55': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_55:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.56': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_56:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.57': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_57:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.58': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_58:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.59': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_59:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.60': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_60:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.61': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_61:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.62': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_62:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.63': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_63:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.64': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_64:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.65': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_65:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.66': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_66:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.67': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_67:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.68': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_68:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.69': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_69:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.70': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_70:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.71': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_71:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.72': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_72:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.73': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_73:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.74': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_74:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.75': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_75:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.76': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_76:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.77': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_77:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.78': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_78:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.79': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_79:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.80': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_80:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.81': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_81:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.82': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_82:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.83': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_83:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.84': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_84:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.85': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_85:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.86': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_86:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.87': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_87:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.88': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_88:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.89': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_89:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.90': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_90:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.91': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_91:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.92': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_92:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.93': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_93:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.94': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_94:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.95': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_95:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.96': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_96:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.97': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_97:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.98': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_98:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.99': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_99:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.100': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_100:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.101': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_101:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.102': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_102:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.103': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_103:0' shape=(None,) dtype=float32\u003e), 'embedded_sentence.104': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, te\n",
            "1053/1053 [==============================] - 12s 7ms/step\n",
            "I0430 10:30:32.207958 1237263 kernel.cc:712] Start Yggdrasil model training\n",
            "I0430 10:30:32.208027 1237263 kernel.cc:713] Collect training examples\n",
            "I0430 10:30:32.208499 1237263 kernel.cc:374] Number of batches: 1053\n",
            "I0430 10:30:32.208526 1237263 kernel.cc:375] Number of examples: 67349\n",
            "I0430 10:30:32.463872 1237263 kernel.cc:735] Dataset:\n",
            "Number of records: 67349\n",
            "Number of columns: 513\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 512 (99.8051%)\n",
            "\tCATEGORICAL: 1 (0.194932%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 512 (99.8051%)\n",
            "\t0: \"embedded_sentence.0\" NUMERICAL mean:-0.00405803 min:-0.110598 max:0.113378 sd:0.0382544\n",
            "\t1: \"embedded_sentence.1\" NUMERICAL mean:0.0020755 min:-0.120324 max:0.106003 sd:0.0434171\n",
            "\t2: \"embedded_sentence.10\" NUMERICAL mean:0.0143459 min:-0.1118 max:0.118193 sd:0.039633\n",
            "\t3: \"embedded_sentence.100\" NUMERICAL mean:0.003884 min:-0.104019 max:0.127238 sd:0.0431\n",
            "\t4: \"embedded_sentence.101\" NUMERICAL mean:-0.0132592 min:-0.133774 max:0.125128 sd:0.0465773\n",
            "\t5: \"embedded_sentence.102\" NUMERICAL mean:0.00732224 min:-0.114158 max:0.135181 sd:0.0462208\n",
            "\t6: \"embedded_sentence.103\" NUMERICAL mean:-0.00316622 min:-0.115661 max:0.110651 sd:0.0393422\n",
            "\t7: \"embedded_sentence.104\" NUMERICAL mean:-0.000406039 min:-0.115186 max:0.115727 sd:0.0404569\n",
            "\t8: \"embedded_sentence.105\" NUMERICAL mean:0.01286 min:-0.10478 max:0.116059 sd:0.0408527\n",
            "\t9: \"embedded_sentence.106\" NUMERICAL mean:-0.0200857 min:-0.112344 max:0.115696 sd:0.0348447\n",
            "\t10: \"embedded_sentence.107\" NUMERICAL mean:-0.000881199 min:-0.117538 max:0.128118 sd:0.0397207\n",
            "\t11: \"embedded_sentence.108\" NUMERICAL mean:-0.0153816 min:-0.119853 max:0.111478 sd:0.0408014\n",
            "\t12: \"embedded_sentence.109\" NUMERICAL mean:0.0226631 min:-0.115775 max:0.109245 sd:0.0344709\n",
            "\t13: \"embedded_sentence.11\" NUMERICAL mean:7.16189e-05 min:-0.10631 max:0.107239 sd:0.0399338\n",
            "\t14: \"embedded_sentence.110\" NUMERICAL mean:-0.0117186 min:-0.12628 max:0.0972872 sd:0.043443\n",
            "\t15: \"embedded_sentence.111\" NUMERICAL mean:-0.0195 min:-0.138677 max:0.111032 sd:0.0530712\n",
            "\t16: \"embedded_sentence.112\" NUMERICAL mean:-0.00883525 min:-0.125434 max:0.115491 sd:0.039556\n",
            "\t17: \"embedded_sentence.113\" NUMERICAL mean:-0.0004395 min:-0.106039 max:0.1141 sd:0.0441183\n",
            "\t18: \"embedded_sentence.114\" NUMERICAL mean:-0.00404027 min:-0.131798 max:0.106558 sd:0.040391\n",
            "\t19: \"embedded_sentence.115\" NUMERICAL mean:0.0164961 min:-0.137229 max:0.11088 sd:0.0396261\n",
            "\t20: \"embedded_sentence.116\" NUMERICAL mean:-0.0163338 min:-0.109692 max:0.115104 sd:0.0396108\n",
            "\t21: \"embedded_sentence.117\" NUMERICAL mean:-0.000866381 min:-0.111258 max:0.110021 sd:0.0413076\n",
            "\t22: \"embedded_sentence.118\" NUMERICAL mean:0.00925641 min:-0.117275 max:0.109073 sd:0.0392531\n",
            "\t23: \"embedded_sentence.119\" NUMERICAL mean:0.0111224 min:-0.108271 max:0.11018 sd:0.0438516\n",
            "\t24: \"embedded_sentence.12\" NUMERICAL mean:-0.0115011 min:-0.115238 max:0.115996 sd:0.039107\n",
            "\t25: \"embedded_sentence.120\" NUMERICAL mean:-0.0109583 min:-0.117243 max:0.113314 sd:0.03753\n",
            "\t26: \"embedded_sentence.121\" NUMERICAL mean:0.0143342 min:-0.109885 max:0.121471 sd:0.0401907\n",
            "\t27: \"embedded_sentence.122\" NUMERICAL mean:-0.00603129 min:-0.111126 max:0.106422 sd:0.0401383\n",
            "\t28: \"embedded_sentence.123\" NUMERICAL mean:-0.00175511 min:-0.115219 max:0.103571 sd:0.0388962\n",
            "\t29: \"embedded_sentence.124\" NUMERICAL mean:-0.0119755 min:-0.119062 max:0.122632 sd:0.0447561\n",
            "\t30: \"embedded_sentence.125\" NUMERICAL mean:0.00210507 min:-0.116783 max:0.125758 sd:0.0469826\n",
            "\t31: \"embedded_sentence.126\" NUMERICAL mean:-0.0166424 min:-0.109771 max:0.13027 sd:0.0399639\n",
            "\t32: \"embedded_sentence.127\" NUMERICAL mean:-0.0462275 min:-0.137916 max:0.106133 sd:0.0478679\n",
            "\t33: \"embedded_sentence.128\" NUMERICAL mean:0.0101449 min:-0.134851 max:0.118003 sd:0.0415072\n",
            "\t34: \"embedded_sentence.129\" NUMERICAL mean:0.0119622 min:-0.106398 max:0.122529 sd:0.047894\n",
            "\t35: \"embedded_sentence.13\" NUMERICAL mean:-0.0179365 min:-0.133052 max:0.120982 sd:0.0461472\n",
            "\t36: \"embedded_sentence.130\" NUMERICAL mean:-0.0109302 min:-0.127096 max:0.102555 sd:0.0407236\n",
            "\t37: \"embedded_sentence.131\" NUMERICAL mean:-2.30418e-05 min:-0.0958128 max:0.116109 sd:0.0393919\n",
            "\t38: \"embedded_sentence.132\" NUMERICAL mean:0.00622466 min:-0.118524 max:0.171935 sd:0.0435631\n",
            "\t39: \"embedded_sentence.133\" NUMERICAL mean:0.00537511 min:-0.0999398 max:0.143991 sd:0.0431652\n",
            "\t40: \"embedded_sentence.134\" NUMERICAL mean:0.0111946 min:-0.101547 max:0.105716 sd:0.0365295\n",
            "\t41: \"embedded_sentence.135\" NUMERICAL mean:-0.0123165 min:-0.118347 max:0.113619 sd:0.0422525\n",
            "\t42: \"embedded_sentence.136\" NUMERICAL mean:0.00882626 min:-0.118642 max:0.115052 sd:0.0393646\n",
            "\t43: \"embedded_sentence.137\" NUMERICAL mean:0.0106701 min:-0.108036 max:0.109746 sd:0.0405698\n",
            "\t44: \"embedded_sentence.138\" NUMERICAL mean:-0.0130655 min:-0.148064 max:0.118745 sd:0.047092\n",
            "\t45: \"embedded_sentence.139\" NUMERICAL mean:0.00256777 min:-0.108547 max:0.102547 sd:0.0388182\n",
            "\t46: \"embedded_sentence.14\" NUMERICAL mean:0.000907569 min:-0.124092 max:0.111964 sd:0.0393761\n",
            "\t47: \"embedded_sentence.140\" NUMERICAL mean:-0.00255201 min:-0.113298 max:0.120327 sd:0.0469564\n",
            "\t48: \"embedded_sentence.141\" NUMERICAL mean:-0.0123127 min:-0.124039 max:0.110528 sd:0.047218\n",
            "\t49: \"embedded_sentence.142\" NUMERICAL mean:0.00659571 min:-0.106909 max:0.126327 sd:0.0444828\n",
            "\t50: \"embedded_sentence.143\" NUMERICAL mean:0.00838607 min:-0.121819 max:0.108286 sd:0.0409403\n",
            "\t51: \"embedded_sentence.144\" NUMERICAL mean:-0.00504916 min:-0.117741 max:0.109832 sd:0.0402179\n",
            "\t52: \"embedded_sentence.145\" NUMERICAL mean:-0.0135 min:-0.112358 max:0.108238 sd:0.0393695\n",
            "\t53: \"embedded_sentence.146\" NUMERICAL mean:-0.00551706 min:-0.108132 max:0.103118 sd:0.0375181\n",
            "\t54: \"embedded_sentence.147\" NUMERICAL mean:0.00226707 min:-0.109358 max:0.117688 sd:0.0416268\n",
            "\t55: \"embedded_sentence.148\" NUMERICAL mean:-0.0083477 min:-0.113886 max:0.105174 sd:0.0379074\n",
            "\t56: \"embedded_sentence.149\" NUMERICAL mean:-0.0029158 min:-0.104327 max:0.10898 sd:0.0394245\n",
            "\t57: \"embedded_sentence.15\" NUMERICAL mean:-0.0465314 min:-0.127274 max:0.115007 sd:0.0410307\n",
            "\t58: \"embedded_sentence.150\" NUMERICAL mean:-0.00857055 min:-0.11757 max:0.108207 sd:0.0416898\n",
            "\t59: \"embedded_sentence.151\" NUMERICAL mean:0.00697776 min:-0.104269 max:0.109967 sd:0.0353302\n",
            "\t60: \"embedded_sentence.152\" NUMERICAL mean:-0.0220037 min:-0.122602 max:0.105503 sd:0.0429071\n",
            "\t61: \"embedded_sentence.153\" NUMERICAL mean:-0.00103943 min:-0.109326 max:0.112115 sd:0.0413219\n",
            "\t62: \"embedded_sentence.154\" NUMERICAL mean:-0.010306 min:-0.106116 max:0.112624 sd:0.0392094\n",
            "\t63: \"embedded_sentence.155\" NUMERICAL mean:-0.0128503 min:-0.133511 max:0.129721 sd:0.0417087\n",
            "\t64: \"embedded_sentence.156\" NUMERICAL mean:-0.00796016 min:-0.10801 max:0.111555 sd:0.0401771\n",
            "\t65: \"embedded_sentence.157\" NUMERICAL mean:-0.0263644 min:-0.135057 max:0.131898 sd:0.0473006\n",
            "\t66: \"embedded_sentence.158\" NUMERICAL mean:0.0157188 min:-0.109795 max:0.13194 sd:0.0423631\n",
            "\t67: \"embedded_sentence.159\" NUMERICAL mean:0.00616692 min:-0.0996693 max:0.121898 sd:0.0405747\n",
            "\t68: \"embedded_sentence.16\" NUMERICAL mean:0.0122186 min:-0.132531 max:0.112023 sd:0.0412513\n",
            "\t69: \"embedded_sentence.160\" NUMERICAL mean:0.00140896 min:-0.125797 max:0.10415 sd:0.0422833\n",
            "\t70: \"embedded_sentence.161\" NUMERICAL mean:-0.00968098 min:-0.107129 max:0.109673 sd:0.0389125\n",
            "\t71: \"embedded_sentence.162\" NUMERICAL mean:0.0174977 min:-0.102559 max:0.117249 sd:0.0394065\n",
            "\t72: \"embedded_sentence.163\" NUMERICAL mean:-0.01559 min:-0.117529 max:0.132716 sd:0.0422287\n",
            "\t73: \"embedded_sentence.164\" NUMERICAL mean:0.0103332 min:-0.131635 max:0.117116 sd:0.0432647\n",
            "\t74: \"embedded_sentence.165\" NUMERICAL mean:0.0164754 min:-0.111395 max:0.106868 sd:0.03591\n",
            "\t75: \"embedded_sentence.166\" NUMERICAL mean:-0.0300909 min:-0.110079 max:0.138071 sd:0.0393771\n",
            "\t76: \"embedded_sentence.167\" NUMERICAL mean:-0.00284721 min:-0.113047 max:0.1113 sd:0.0402787\n",
            "\t77: \"embedded_sentence.168\" NUMERICAL mean:0.0128449 min:-0.123295 max:0.101678 sd:0.035443\n",
            "\t78: \"embedded_sentence.169\" NUMERICAL mean:-0.0018307 min:-0.113497 max:0.108755 sd:0.0385736\n",
            "\t79: \"embedded_sentence.17\" NUMERICAL mean:0.0112924 min:-0.118483 max:0.109047 sd:0.0411375\n",
            "\t80: \"embedded_sentence.170\" NUMERICAL mean:-0.0154471 min:-0.123997 max:0.0995884 sd:0.039095\n",
            "\t81: \"embedded_sentence.171\" NUMERICAL mean:-0.0115266 min:-0.135629 max:0.111586 sd:0.0564499\n",
            "\t82: \"embedded_sentence.172\" NUMERICAL mean:-0.00305818 min:-0.108149 max:0.125287 sd:0.0416153\n",
            "\t83: \"embedded_sentence.173\" NUMERICAL mean:-0.0192183 min:-0.128661 max:0.111586 sd:0.0445312\n",
            "\t84: \"embedded_sentence.174\" NUMERICAL mean:-0.00547071 min:-0.106778 max:0.107318 sd:0.0412694\n",
            "\t85: \"embedded_sentence.175\" NUMERICAL mean:0.00303105 min:-0.114183 max:0.11671 sd:0.037753\n",
            "\t86: \"embedded_sentence.176\" NUMERICAL mean:0.0200632 min:-0.119154 max:0.12262 sd:0.0449386\n",
            "\t87: \"embedded_sentence.177\" NUMERICAL mean:0.00830421 min:-0.106867 max:0.108159 sd:0.04212\n",
            "\t88: \"embedded_sentence.178\" NUMERICAL mean:0.0087977 min:-0.119236 max:0.0975505 sd:0.0365596\n",
            "\t89: \"embedded_sentence.179\" NUMERICAL mean:-0.0224472 min:-0.141699 max:0.121597 sd:0.0451563\n",
            "\t90: \"embedded_sentence.18\" NUMERICAL mean:0.0161367 min:-0.103659 max:0.106467 sd:0.0396646\n",
            "\t91: \"embedded_sentence.180\" NUMERICAL mean:0.00700457 min:-0.122243 max:0.106828 sd:0.0406674\n",
            "\t92: \"embedded_sentence.181\" NUMERICAL mean:0.015665 min:-0.123784 max:0.117493 sd:0.0423638\n",
            "\t93: \"embedded_sentence.182\" NUMERICAL mean:0.00455087 min:-0.130433 max:0.129947 sd:0.0468312\n",
            "\t94: \"embedded_sentence.183\" NUMERICAL mean:0.00469912 min:-0.105513 max:0.115268 sd:0.0422015\n",
            "\t95: \"embedded_sentence.184\" NUMERICAL mean:0.00118913 min:-0.132085 max:0.119005 sd:0.0425006\n",
            "\t96: \"embedded_sentence.185\" NUMERICAL mean:-0.0091211 min:-0.105384 max:0.107321 sd:0.0394833\n",
            "\t97: \"embedded_sentence.186\" NUMERICAL mean:0.00847289 min:-0.100142 max:0.11416 sd:0.0354507\n",
            "\t98: \"embedded_sentence.187\" NUMERICAL mean:0.00401229 min:-0.0997345 max:0.0985512 sd:0.0330015\n",
            "\t99: \"embedded_sentence.188\" NUMERICAL mean:0.0375059 min:-0.107009 max:0.147423 sd:0.0457626\n",
            "\t100: \"embedded_sentence.189\" NUMERICAL mean:-0.0108558 min:-0.158798 max:0.124698 sd:0.0429543\n",
            "\t101: \"embedded_sentence.19\" NUMERICAL mean:0.000475908 min:-0.126049 max:0.109106 sd:0.0416907\n",
            "\t102: \"embedded_sentence.190\" NUMERICAL mean:0.0055649 min:-0.102637 max:0.112907 sd:0.0428818\n",
            "\t103: \"embedded_sentence.191\" NUMERICAL mean:0.0115727 min:-0.0992453 max:0.114756 sd:0.0385606\n",
            "\t104: \"embedded_sentence.192\" NUMERICAL mean:0.0188207 min:-0.10799 max:0.126446 sd:0.0480457\n",
            "\t105: \"embedded_sentence.193\" NUMERICAL mean:-0.0231128 min:-0.125829 max:0.0984851 sd:0.0413616\n",
            "\t106: \"embedded_sentence.194\" NUMERICAL mean:-0.0125518 min:-0.118983 max:0.111524 sd:0.0394032\n",
            "\t107: \"embedded_sentence.195\" NUMERICAL mean:-0.00734374 min:-0.140773 max:0.124731 sd:0.048662\n",
            "\t108: \"embedded_sentence.196\" NUMERICAL mean:0.0147101 min:-0.109208 max:0.114207 sd:0.0392372\n",
            "\t109: \"embedded_sentence.197\" NUMERICAL mean:0.00382817 min:-0.0960263 max:0.109744 sd:0.0343786\n",
            "\t110: \"embedded_sentence.198\" NUMERICAL mean:0.0148358 min:-0.121261 max:0.137886 sd:0.0396124\n",
            "\t111: \"embedded_sentence.199\" NUMERICAL mean:0.0139377 min:-0.133057 max:0.129123 sd:0.0434494\n",
            "\t112: \"embedded_sentence.2\" NUMERICAL mean:0.00763253 min:-0.102393 max:0.126418 sd:0.0391092\n",
            "\t113: \"embedded_sentence.20\" NUMERICAL mean:0.0067624 min:-0.117482 max:0.140442 sd:0.0473874\n",
            "\t114: \"embedded_sentence.200\" NUMERICAL mean:-0.022174 min:-0.135182 max:0.0998059 sd:0.0447171\n",
            "\t115: \"embedded_sentence.201\" NUMERICAL mean:0.00918432 min:-0.129768 max:0.104146 sd:0.0407455\n",
            "\t116: \"embedded_sentence.202\" NUMERICAL mean:6.68976e-05 min:-0.108528 max:0.112123 sd:0.039669\n",
            "\t117: \"embedded_sentence.203\" NUMERICAL mean:-0.0211792 min:-0.138447 max:0.151201 sd:0.0475548\n",
            "\t118: \"embedded_sentence.204\" NUMERICAL mean:0.0149458 min:-0.114192 max:0.121993 sd:0.0451805\n",
            "\t119: \"embedded_sentence.205\" NUMERICAL mean:-0.000877425 min:-0.106281 max:0.110069 sd:0.0399283\n",
            "\t120: \"embedded_sentence.206\" NUMERICAL mean:0.00135042 min:-0.122458 max:0.133155 sd:0.0490798\n",
            "\t121: \"embedded_sentence.207\" NUMERICAL mean:-0.00564686 min:-0.0980346 max:0.124534 sd:0.0381495\n",
            "\t122: \"embedded_sentence.208\" NUMERICAL mean:-0.0137386 min:-0.104712 max:0.116268 sd:0.0380542\n",
            "\t123: \"embedded_sentence.209\" NUMERICAL mean:-0.000932724 min:-0.120575 max:0.106782 sd:0.0389735\n",
            "\t124: \"embedded_sentence.21\" NUMERICAL mean:-0.0103802 min:-0.141084 max:0.11384 sd:0.0543033\n",
            "\t125: \"embedded_sentence.210\" NUMERICAL mean:-0.0221436 min:-0.11615 max:0.110612 sd:0.0375885\n",
            "\t126: \"embedded_sentence.211\" NUMERICAL mean:0.00739621 min:-0.107881 max:0.139283 sd:0.0380559\n",
            "\t127: \"embedded_sentence.212\" NUMERICAL mean:0.000771754 min:-0.130277 max:0.118151 sd:0.0457612\n",
            "\t128: \"embedded_sentence.213\" NUMERICAL mean:-0.00631693 min:-0.113811 max:0.122369 sd:0.0420019\n",
            "\t129: \"embedded_sentence.214\" NUMERICAL mean:-0.0190752 min:-0.130814 max:0.12256 sd:0.0462656\n",
            "\t130: \"embedded_sentence.215\" NUMERICAL mean:0.00351438 min:-0.119497 max:0.112531 sd:0.0389063\n",
            "\t131: \"embedded_sentence.216\" NUMERICAL mean:-0.00563816 min:-0.113327 max:0.108574 sd:0.0398438\n",
            "\t132: \"embedded_sentence.217\" NUMERICAL mean:-0.0128165 min:-0.152494 max:0.112129 sd:0.0435284\n",
            "\t133: \"embedded_sentence.218\" NUMERICAL mean:-0.000746104 min:-0.115932 max:0.103357 sd:0.0396475\n",
            "\t134: \"embedded_sentence.219\" NUMERICAL mean:0.00706257 min:-0.105737 max:0.115808 sd:0.0415758\n",
            "\t135: \"embedded_sentence.22\" NUMERICAL mean:0.00470285 min:-0.108062 max:0.127381 sd:0.0465233\n",
            "\t136: \"embedded_sentence.220\" NUMERICAL mean:0.000614336 min:-0.120866 max:0.10502 sd:0.036915\n",
            "\t137: \"embedded_sentence.221\" NUMERICAL mean:-0.00315481 min:-0.110209 max:0.126778 sd:0.0398762\n",
            "\t138: \"embedded_sentence.222\" NUMERICAL mean:-0.0055338 min:-0.112973 max:0.111057 sd:0.0367833\n",
            "\t139: \"embedded_sentence.223\" NUMERICAL mean:0.0129532 min:-0.108908 max:0.112232 sd:0.0406737\n",
            "\t140: \"embedded_sentence.224\" NUMERICAL mean:-0.0195448 min:-0.112833 max:0.122565 sd:0.0423641\n",
            "\t141: \"embedded_sentence.225\" NUMERICAL mean:0.00715641 min:-0.136763 max:0.123146 sd:0.0455536\n",
            "\t142: \"embedded_sentence.226\" NUMERICAL mean:0.0105978 min:-0.121166 max:0.125465 sd:0.0433322\n",
            "\t143: \"embedded_sentence.227\" NUMERICAL mean:-0.00822156 min:-0.131487 max:0.125193 sd:0.0440489\n",
            "\t144: \"embedded_sentence.228\" NUMERICAL mean:0.0119113 min:-0.109956 max:0.107868 sd:0.0382855\n",
            "\t145: \"embedded_sentence.229\" NUMERICAL mean:-0.00739044 min:-0.116468 max:0.109886 sd:0.0406385\n",
            "\t146: \"embedded_sentence.23\" NUMERICAL mean:0.00203851 min:-0.116632 max:0.116226 sd:0.0400387\n",
            "\t147: \"embedded_sentence.230\" NUMERICAL mean:0.00819752 min:-0.100016 max:0.125019 sd:0.041894\n",
            "\t148: \"embedded_sentence.231\" NUMERICAL mean:-0.00420582 min:-0.139816 max:0.138647 sd:0.0446602\n",
            "\t149: \"embedded_sentence.232\" NUMERICAL mean:0.00810722 min:-0.11301 max:0.106853 sd:0.0400325\n",
            "\t150: \"embedded_sentence.233\" NUMERICAL mean:0.0561205 min:-0.110581 max:0.182054 sd:0.0645425\n",
            "\t151: \"embedded_sentence.234\" NUMERICAL mean:0.0202212 min:-0.109987 max:0.116562 sd:0.0374199\n",
            "\t152: \"embedded_sentence.235\" NUMERICAL mean:-0.0125547 min:-0.104766 max:0.115993 sd:0.0383767\n",
            "\t153: \"embedded_sentence.236\" NUMERICAL mean:0.00228544 min:-0.126092 max:0.125991 sd:0.0403744\n",
            "\t154: \"embedded_sentence.237\" NUMERICAL mean:-0.00306858 min:-0.107907 max:0.109284 sd:0.0409564\n",
            "\t155: \"embedded_sentence.238\" NUMERICAL mean:-0.00930815 min:-0.15644\n",
            "I0430 10:30:32.464688 1237263 kernel.cc:738] Configure learner\n",
            "I0430 10:30:32.464899 1237263 kernel.cc:763] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"embedded_sentence\\\\.0\"\n",
            "features: \"embedded_sentence\\\\.1\"\n",
            "features: \"embedded_sentence\\\\.10\"\n",
            "features: \"embedded_sentence\\\\.100\"\n",
            "features: \"embedded_sentence\\\\.101\"\n",
            "features: \"embedded_sentence\\\\.102\"\n",
            "features: \"embedded_sentence\\\\.103\"\n",
            "features: \"embedded_sentence\\\\.104\"\n",
            "features: \"embedded_sentence\\\\.105\"\n",
            "features: \"embedded_sentence\\\\.106\"\n",
            "features: \"embedded_sentence\\\\.107\"\n",
            "features: \"embedded_sentence\\\\.108\"\n",
            "features: \"embedded_sentence\\\\.109\"\n",
            "features: \"embedded_sentence\\\\.11\"\n",
            "features: \"embedded_sentence\\\\.110\"\n",
            "features: \"embedded_sentence\\\\.111\"\n",
            "features: \"embedded_sentence\\\\.112\"\n",
            "features: \"embedded_sentence\\\\.113\"\n",
            "features: \"embedded_sentence\\\\.114\"\n",
            "features: \"embedded_sentence\\\\.115\"\n",
            "features: \"embedded_sentence\\\\.116\"\n",
            "features: \"embedded_sentence\\\\.117\"\n",
            "features: \"embedded_sentence\\\\.118\"\n",
            "features: \"embedded_sentence\\\\.119\"\n",
            "features: \"embedded_sentence\\\\.12\"\n",
            "features: \"embedded_sentence\\\\.120\"\n",
            "features: \"embedded_sentence\\\\.121\"\n",
            "features: \"embedded_sentence\\\\.122\"\n",
            "features: \"embedded_sentence\\\\.123\"\n",
            "features: \"embedded_sentence\\\\.124\"\n",
            "features: \"embedded_sentence\\\\.125\"\n",
            "features: \"embedded_sentence\\\\.126\"\n",
            "features: \"embedded_sentence\\\\.127\"\n",
            "features: \"embedded_sentence\\\\.128\"\n",
            "features: \"embedded_sentence\\\\.129\"\n",
            "features: \"embedded_sentence\\\\.13\"\n",
            "features: \"embedded_sentence\\\\.130\"\n",
            "features: \"embedded_sentence\\\\.131\"\n",
            "features: \"embedded_sentence\\\\.132\"\n",
            "features: \"embedded_sentence\\\\.133\"\n",
            "features: \"embedded_sentence\\\\.134\"\n",
            "features: \"embedded_sentence\\\\.135\"\n",
            "features: \"embedded_sentence\\\\.136\"\n",
            "features: \"embedded_sentence\\\\.137\"\n",
            "features: \"embedded_sentence\\\\.138\"\n",
            "features: \"embedded_sentence\\\\.139\"\n",
            "features: \"embedded_sentence\\\\.14\"\n",
            "features: \"embedded_sentence\\\\.140\"\n",
            "features: \"embedded_sentence\\\\.141\"\n",
            "features: \"embedded_sentence\\\\.142\"\n",
            "features: \"embedded_sentence\\\\.143\"\n",
            "features: \"embedded_sentence\\\\.144\"\n",
            "features: \"embedded_sentence\\\\.145\"\n",
            "features: \"embedded_sentence\\\\.146\"\n",
            "features: \"embedded_sentence\\\\.147\"\n",
            "features: \"embedded_sentence\\\\.148\"\n",
            "features: \"embedded_sentence\\\\.149\"\n",
            "features: \"embedded_sentence\\\\.15\"\n",
            "features: \"embedded_sentence\\\\.150\"\n",
            "features: \"embedded_sentence\\\\.151\"\n",
            "features: \"embedded_sentence\\\\.152\"\n",
            "features: \"embedded_sentence\\\\.153\"\n",
            "features: \"embedded_sentence\\\\.154\"\n",
            "features: \"embedded_sentence\\\\.155\"\n",
            "features: \"embedded_sentence\\\\.156\"\n",
            "features: \"embedded_sentence\\\\.157\"\n",
            "features: \"embedded_sentence\\\\.158\"\n",
            "features: \"embedded_sentence\\\\.159\"\n",
            "features: \"embedded_sentence\\\\.16\"\n",
            "features: \"embedded_sentence\\\\.160\"\n",
            "features: \"embedded_sentence\\\\.161\"\n",
            "features: \"embedded_sentence\\\\.162\"\n",
            "features: \"embedded_sentence\\\\.163\"\n",
            "features: \"embedded_sentence\\\\.164\"\n",
            "features: \"embedded_sentence\\\\.165\"\n",
            "features: \"embedded_sentence\\\\.166\"\n",
            "features: \"embedded_sentence\\\\.167\"\n",
            "features: \"embedded_sentence\\\\.168\"\n",
            "features: \"embedded_sentence\\\\.169\"\n",
            "features: \"embedded_sentence\\\\.17\"\n",
            "features: \"embedded_sentence\\\\.170\"\n",
            "features: \"embedded_sentence\\\\.171\"\n",
            "features: \"embedded_sentence\\\\.172\"\n",
            "features: \"embedded_sentence\\\\.173\"\n",
            "features: \"embedded_sentence\\\\.174\"\n",
            "features: \"embedded_sentence\\\\.175\"\n",
            "features: \"embedded_sentence\\\\.176\"\n",
            "features: \"embedded_sentence\\\\.177\"\n",
            "features: \"embedded_sentence\\\\.178\"\n",
            "features: \"embedded_sentence\\\\.179\"\n",
            "features: \"embedded_sentence\\\\.18\"\n",
            "features: \"embedded_sentence\\\\.180\"\n",
            "features: \"embedded_sentence\\\\.181\"\n",
            "features: \"embedded_sentence\\\\.182\"\n",
            "features: \"embedded_sentence\\\\.183\"\n",
            "features: \"embedded_sentence\\\\.184\"\n",
            "features: \"embedded_sentence\\\\.185\"\n",
            "features: \"embedded_sentence\\\\.186\"\n",
            "features: \"embedded_sentence\\\\.187\"\n",
            "features: \"embedded_sentence\\\\.188\"\n",
            "features: \"embedded_sentence\\\\.189\"\n",
            "features: \"embedded_sentence\\\\.19\"\n",
            "features: \"embedded_sentence\\\\.190\"\n",
            "features: \"embedded_sentence\\\\.191\"\n",
            "features: \"embedded_sentence\\\\.192\"\n",
            "features: \"embedded_sentence\\\\.193\"\n",
            "features: \"embedded_sentence\\\\.194\"\n",
            "features: \"embedded_sentence\\\\.195\"\n",
            "features: \"embedded_sentence\\\\.196\"\n",
            "features: \"embedded_sentence\\\\.197\"\n",
            "features: \"embedded_sentence\\\\.198\"\n",
            "features: \"embedded_sentence\\\\.199\"\n",
            "features: \"embedded_sentence\\\\.2\"\n",
            "features: \"embedded_sentence\\\\.20\"\n",
            "features: \"embedded_sentence\\\\.200\"\n",
            "features: \"embedded_sentence\\\\.201\"\n",
            "features: \"embedded_sentence\\\\.202\"\n",
            "features: \"embedded_sentence\\\\.203\"\n",
            "features: \"embedded_sentence\\\\.204\"\n",
            "features: \"embedded_sentence\\\\.205\"\n",
            "features: \"embedded_sentence\\\\.206\"\n",
            "features: \"embedded_sentence\\\\.207\"\n",
            "features: \"embedded_sentence\\\\.208\"\n",
            "features: \"embedded_sentence\\\\.209\"\n",
            "features: \"embedded_sentence\\\\.21\"\n",
            "features: \"embedded_sentence\\\\.210\"\n",
            "features: \"embedded_sentence\\\\.211\"\n",
            "features: \"embedded_sentence\\\\.212\"\n",
            "features: \"embedded_sentence\\\\.213\"\n",
            "features: \"embedded_sentence\\\\.214\"\n",
            "features: \"embedded_sentence\\\\.215\"\n",
            "features: \"embedded_sentence\\\\.216\"\n",
            "features: \"embedded_sentence\\\\.217\"\n",
            "features: \"embedded_sentence\\\\.218\"\n",
            "features: \"embedded_sentence\\\\.219\"\n",
            "features: \"embedded_sentence\\\\.22\"\n",
            "features: \"embedded_sentence\\\\.220\"\n",
            "features: \"embedded_sentence\\\\.221\"\n",
            "features: \"embedded_sentence\\\\.222\"\n",
            "features: \"embedded_sentence\\\\.223\"\n",
            "features: \"embedded_sentence\\\\.224\"\n",
            "features: \"embedded_sentence\\\\.225\"\n",
            "features: \"embedded_sentence\\\\.226\"\n",
            "features: \"embedded_sentence\\\\.227\"\n",
            "features: \"embedded_sentence\\\\.228\"\n",
            "features: \"embedded_sentence\\\\.229\"\n",
            "features: \"embedded_sentence\\\\.23\"\n",
            "features: \"embedded_sentence\\\\.230\"\n",
            "features: \"embedded_sentence\\\\.231\"\n",
            "features: \"embedded_sentence\\\\.232\"\n",
            "features: \"embedded_sentence\\\\.233\"\n",
            "features: \"embedded_sentence\\\\.234\"\n",
            "features: \"embedded_sentence\\\\.235\"\n",
            "features: \"embedded_sentence\\\\.236\"\n",
            "features: \"embedded_sentence\\\\.237\"\n",
            "features: \"embedded_sentence\\\\.238\"\n",
            "features: \"embedded_sentence\\\\.239\"\n",
            "features: \"embedded_sentence\\\\.24\"\n",
            "features: \"embedded_sentence\\\\.240\"\n",
            "features: \"embedded_sentence\\\\.241\"\n",
            "features: \"embedded_sentence\\\\.242\"\n",
            "features: \"embedded_sentence\\\\.243\"\n",
            "features: \"embedded_sentence\\\\.244\"\n",
            "features: \"embedded_sentence\\\\.245\"\n",
            "features: \"embedded_sentence\\\\.246\"\n",
            "features: \"embedded_sentence\\\\.247\"\n",
            "features: \"embedded_sentence\\\\.248\"\n",
            "features: \"embedded_sentence\\\\.249\"\n",
            "features: \"embedded_sentence\\\\.25\"\n",
            "features: \"embedded_sentence\\\\.250\"\n",
            "features: \"embedded_sentence\\\\.251\"\n",
            "features: \"embedded_sentence\\\\.252\"\n",
            "features: \"embedded_sentence\\\\.253\"\n",
            "features: \"embedded_sentence\\\\.254\"\n",
            "features: \"embedded_sentence\\\\.255\"\n",
            "features: \"embedded_sentence\\\\.256\"\n",
            "features: \"embedded_sentence\\\\.257\"\n",
            "features: \"embedded_sentence\\\\.258\"\n",
            "features: \"embedded_sentence\\\\.259\"\n",
            "features: \"embedded_sentence\\\\.26\"\n",
            "features: \"embedded_sentence\\\\.260\"\n",
            "features: \"embedded_sentence\\\\.261\"\n",
            "features: \"embedded_sentence\\\\.262\"\n",
            "features: \"embedded_sentence\\\\.263\"\n",
            "features: \"embedded_sentence\\\\.264\"\n",
            "features: \"embedded_sentence\\\\.265\"\n",
            "features: \"embedded_sentence\\\\.266\"\n",
            "features: \"embedded_sentence\\\\.267\"\n",
            "features: \"embedded_sentence\\\\.268\"\n",
            "features: \"embedded_sentence\\\\.269\"\n",
            "features: \"embedded_sentence\\\\.27\"\n",
            "features: \"embedded_sentence\\\\.270\"\n",
            "features: \"embedded_sentence\\\\.271\"\n",
            "features: \"embedded_sentence\\\\.272\"\n",
            "features: \"embedded_sentence\\\\.273\"\n",
            "features: \"embedded_sentence\\\\.274\"\n",
            "features: \"embedded_sentence\\\\.275\"\n",
            "features: \"embedded_sentence\\\\.276\"\n",
            "features: \"embedded_sentence\\\\.277\"\n",
            "features: \"embedded_sentence\\\\.278\"\n",
            "features: \"embedded_sentence\\\\.279\"\n",
            "features: \"embedded_sentence\\\\.28\"\n",
            "features: \"embedded_sentence\\\\.280\"\n",
            "features: \"embedded_sentence\\\\.281\"\n",
            "features: \"embedded_sentence\\\\.282\"\n",
            "features: \"embedded_sentence\\\\.283\"\n",
            "features: \"embedded_sentence\\\\.284\"\n",
            "features: \"embedded_sentence\\\\.285\"\n",
            "features: \"embedded_sentence\\\\.286\"\n",
            "features: \"embedded_sentence\\\\.287\"\n",
            "features: \"embedded_sentence\\\\.288\"\n",
            "features: \"embedded_sentence\\\\.289\"\n",
            "features: \"embedded_sentence\\\\.29\"\n",
            "features: \"embedded_sentence\\\\.290\"\n",
            "features: \"embedded_sentence\\\\.291\"\n",
            "features: \"embedded_sentence\\\\.292\"\n",
            "features: \"embedded_sentence\\\\.293\"\n",
            "features: \"embedded_sentence\\\\.294\"\n",
            "features: \"embedded_sentence\\\\.295\"\n",
            "features: \"embedded_sentence\\\\.296\"\n",
            "features: \"embedded_sentence\\\\.297\"\n",
            "features: \"embedded_sentence\\\\.298\"\n",
            "features: \"embedded_sentence\\\\.299\"\n",
            "features: \"embedded_sentence\\\\.3\"\n",
            "features: \"embedded_sentence\\\\.30\"\n",
            "features: \"embedded_sentence\\\\.300\"\n",
            "features: \"embedded_sentence\\\\.301\"\n",
            "features: \"embedded_sentence\\\\.302\"\n",
            "features: \"embedded_sentence\\\\.303\"\n",
            "features: \"embedded_sentence\\\\.304\"\n",
            "features: \"embedded_sentence\\\\.305\"\n",
            "features: \"embedded_sentence\\\\.306\"\n",
            "features: \"embedded_sentence\\\\.307\"\n",
            "features: \"embedded_sentence\\\\.308\"\n",
            "features: \"embedded_sentence\\\\.309\"\n",
            "features: \"embedded_sentence\\\\.31\"\n",
            "features: \"embedded_sentence\\\\.310\"\n",
            "features: \"embedded_sentence\\\\.311\"\n",
            "features: \"embedded_sentence\\\\.312\"\n",
            "features: \"embedded_sentence\\\\.313\"\n",
            "features: \"embedded_sentence\\\\.314\"\n",
            "features: \"embedded_sentence\\\\.315\"\n",
            "features: \"embedded_sentence\\\\.316\"\n",
            "features: \"embedded_sentence\\\\.317\"\n",
            "features: \"embedded_sentence\\\\.318\"\n",
            "features: \"embedded_sentence\\\\.319\"\n",
            "features: \"embedded_sentence\\\\.32\"\n",
            "features: \"embedded_sentence\\\\.320\"\n",
            "features: \"embedded_sentence\\\\.321\"\n",
            "features: \"embedded_sentence\\\\.322\"\n",
            "features: \"embedded_sentence\\\\.323\"\n",
            "features: \"embedded_sentence\\\\.324\"\n",
            "features: \"embedded_sentence\\\\.325\"\n",
            "features: \"embedded_sentence\\\\.326\"\n",
            "features: \"embedded_sentence\\\\.327\"\n",
            "features: \"embedded_sentence\\\\.328\"\n",
            "features: \"embedded_sentence\\\\.329\"\n",
            "features: \"embedded_sentence\\\\.33\"\n",
            "features: \"embedded_sentence\\\\.330\"\n",
            "features: \"embedded_sentence\\\\.331\"\n",
            "features: \"embedded_sentence\\\\.332\"\n",
            "features: \"embedded_sentence\\\\.333\"\n",
            "features: \"embedded_sentence\\\\.334\"\n",
            "features: \"embedded_sentence\\\\.335\"\n",
            "features: \"embedded_sentence\\\\.336\"\n",
            "features: \"embedded_sentence\\\\.337\"\n",
            "features: \"embedded_sentence\\\\.338\"\n",
            "features: \"embedded_sentence\\\\.339\"\n",
            "features: \"embedded_sentence\\\\.34\"\n",
            "features: \"embedded_sentence\\\\.340\"\n",
            "features: \"embedded_sentence\\\\.341\"\n",
            "features: \"embedded_sentence\\\\.342\"\n",
            "features: \"embedded_sentence\\\\.343\"\n",
            "features: \"embedded_sentence\\\\.344\"\n",
            "features: \"embedded_sentence\\\\.345\"\n",
            "features: \"embedded_sentence\\\\.346\"\n",
            "features: \"embedded_sentence\\\\.347\"\n",
            "features: \"embedded_sentence\\\\.348\"\n",
            "features: \"embedded_sentence\\\\.349\"\n",
            "features: \"embedded_sentence\\\\.35\"\n",
            "features: \"embedded_sentence\\\\.350\"\n",
            "features: \"embedded_sentence\\\\.351\"\n",
            "features: \"embedded_sentence\\\\.352\"\n",
            "features: \"embedded_sentence\\\\.353\"\n",
            "features: \"embedded_sentence\\\\.354\"\n",
            "features: \"embedded_sentence\\\\.355\"\n",
            "features: \"embedded_sentence\\\\.356\"\n",
            "features: \"embedded_sentence\\\\.357\"\n",
            "features: \"embedded_sentence\\\\.358\"\n",
            "features: \"embedded_sentence\\\\.359\"\n",
            "features: \"embedded_sentence\\\\.36\"\n",
            "features: \"embedded_sentence\\\\.360\"\n",
            "features: \"embedded_sentence\\\\.361\"\n",
            "features: \"embedded_sentence\\\\.362\"\n",
            "features: \"embedded_sentence\\\\.363\"\n",
            "features: \"embedded_sentence\\\\.364\"\n",
            "features: \"embedded_sentence\\\\.365\"\n",
            "features: \"embedded_sentence\\\\.366\"\n",
            "features: \"embedded_sentence\\\\.367\"\n",
            "features: \"embedded_sentence\\\\.368\"\n",
            "features: \"embedded_sentence\\\\.369\"\n",
            "features: \"embedded_sentence\\\\.37\"\n",
            "features: \"embedded_sentence\\\\.370\"\n",
            "features: \"embedded_sentence\\\\.371\"\n",
            "features: \"embedded_sentence\\\\.372\"\n",
            "features: \"embedded_sentence\\\\.373\"\n",
            "features: \"embedded_sentence\\\\.374\"\n",
            "features: \"embedded_sentence\\\\.375\"\n",
            "features: \"embedded_sentence\\\\.376\"\n",
            "features: \"embedded_sentence\\\\.377\"\n",
            "features: \"embedded_sentence\\\\.378\"\n",
            "features: \"embedded_sentence\\\\.379\"\n",
            "features: \"embedded_sentence\\\\.38\"\n",
            "features: \"embedded_sentence\\\\.380\"\n",
            "features: \"embedded_sentence\\\\.381\"\n",
            "features: \"embedded_sentence\\\\.382\"\n",
            "features: \"embedded_sentence\\\\.383\"\n",
            "features: \"embedded_sentence\\\\.384\"\n",
            "features: \"embedded_sentence\\\\.385\"\n",
            "features: \"embedded_sentence\\\\.386\"\n",
            "features: \"embedded_sentence\\\\.387\"\n",
            "features: \"embedded_sentence\\\\.388\"\n",
            "features: \"embedded_sentence\\\\.389\"\n",
            "features: \"embedded_sentence\\\\.39\"\n",
            "features: \"embedded_sentence\\\\.390\"\n",
            "features: \"embedded_sentence\\\\.391\"\n",
            "features: \"embedded_sentence\\\\.392\"\n",
            "features: \"embedded_sentence\\\\.393\"\n",
            "features: \"embedded_sentence\\\\.394\"\n",
            "features: \"embedded_sentence\\\\.395\"\n",
            "features: \"embedded_sentence\\\\.396\"\n",
            "features: \"embedded_sentence\\\\.397\"\n",
            "features: \"embedded_sentence\\\\.398\"\n",
            "features: \"embedded_sentence\\\\.399\"\n",
            "features: \"embedded_sentence\\\\.4\"\n",
            "features: \"embedded_sentence\\\\.40\"\n",
            "features: \"embedded_sentence\\\\.400\"\n",
            "features: \"embedded_sentence\\\\.401\"\n",
            "features: \"embedded_sentence\\\\.402\"\n",
            "features: \"embedded_sentence\\\\.403\"\n",
            "features: \"embedded_sentence\\\\.404\"\n",
            "features: \"embedded_sentence\\\\.405\"\n",
            "features: \"embedded_sentence\\\\.406\"\n",
            "features: \"embedded_sentence\\\\.407\"\n",
            "features: \"embedded_sentence\\\\.408\"\n",
            "features: \"embedded_sentence\\\\.409\"\n",
            "features: \"embedded_sentence\\\\.41\"\n",
            "features: \"embedded_sentence\\\\.410\"\n",
            "features: \"embedded_sentence\\\\.411\"\n",
            "features: \"embedded_sentence\\\\.412\"\n",
            "features: \"embedded_sentence\\\\.413\"\n",
            "features: \"embedded_sentence\\\\.414\"\n",
            "features: \"embedded_sentence\\\\.415\"\n",
            "features: \"embedded_sentence\\\\.416\"\n",
            "features: \"embedded_sentence\\\\.417\"\n",
            "features: \"embedded_sentence\\\\.418\"\n",
            "features: \"embedded_sentence\\\\.419\"\n",
            "features: \"embedded_sentence\\\\.42\"\n",
            "features: \"embedded_sentence\\\\.420\"\n",
            "features: \"embedded_sentence\\\\.421\"\n",
            "features: \"embedded_sentence\\\\.422\"\n",
            "features: \"embedded_sentence\\\\.423\"\n",
            "features: \"embedded_sentence\\\\.424\"\n",
            "features: \"embedded_sentence\\\\.425\"\n",
            "features: \"embedded_sentence\\\\.426\"\n",
            "features: \"embedded_sentence\\\\.427\"\n",
            "features: \"embedded_sentence\\\\.428\"\n",
            "features: \"embedded_sentence\\\\.429\"\n",
            "features: \"embedded_sentence\\\\.43\"\n",
            "features: \"embedded_sentence\\\\.430\"\n",
            "features: \"embedded_sentence\\\\.431\"\n",
            "features: \"embedded_sentence\\\\.432\"\n",
            "features: \"embedded_sentence\\\\.433\"\n",
            "features: \"embedded_sentence\\\\.434\"\n",
            "features: \"embedded_sentence\\\\.435\"\n",
            "features: \"embedded_sentence\\\\.436\"\n",
            "features: \"embedded_sentence\\\\.437\"\n",
            "features: \"embedded_sentence\\\\.438\"\n",
            "features: \"embedded_sentence\\\\.439\"\n",
            "features: \"embedded_sentence\\\\.44\"\n",
            "features: \"embedded_sentence\\\\.440\"\n",
            "features: \"embedded_sentence\\\\.441\"\n",
            "features: \"embedded_sentence\\\\.442\"\n",
            "features: \"embedded_sentence\\\\.443\"\n",
            "features: \"embedded_sentence\\\\.444\"\n",
            "features: \"embedded_sentence\\\\.445\"\n",
            "features: \"embedded_sentence\\\\.446\"\n",
            "features: \"embedded_sentence\\\\.447\"\n",
            "features: \"embedded_sentence\\\\.448\"\n",
            "features: \"embedded_sentence\\\\.449\"\n",
            "features: \"embedded_sentence\\\\.45\"\n",
            "features: \"embedded_sentence\\\\.450\"\n",
            "features: \"embedded_sentence\\\\.451\"\n",
            "features: \"embedded_sentence\\\\.452\"\n",
            "features: \"embedded_sentence\\\\.453\"\n",
            "features: \"embedded_sentence\\\\.454\"\n",
            "features: \"embedded_sentence\\\\.455\"\n",
            "features: \"embedded_sentence\\\\.456\"\n",
            "features: \"embedded_sentence\\\\.457\"\n",
            "features: \"embedded_sentence\\\\.458\"\n",
            "features: \"embedded_sentence\\\\.459\"\n",
            "features: \"embedded_sentence\\\\.46\"\n",
            "features: \"embedded_sentence\\\\.460\"\n",
            "features: \"embedded_sentence\\\\.461\"\n",
            "features: \"embedded_sentence\\\\.462\"\n",
            "features: \"embedded_sentence\\\\.463\"\n",
            "features: \"embedded_sentence\\\\.464\"\n",
            "features: \"embedded_sentence\\\\.465\"\n",
            "features: \"embedded_sentence\\\\.466\"\n",
            "features: \"embedded_sentence\\\\.467\"\n",
            "features: \"embedded_sentence\\\\.468\"\n",
            "features: \"embedded_sentence\\\\.469\"\n",
            "features: \"embedded_sentence\\\\.47\"\n",
            "features: \"embedded_sentence\\\\.470\"\n",
            "features: \"embedded_sentence\\\\.471\"\n",
            "features: \"embedded\n",
            "I0430 10:30:32.465391 1237263 kernel.cc:766] Deployment config:\n",
            "I0430 10:30:32.465403 1237263 kernel.cc:788] Train model\n",
            "I0430 10:30:32.482968 1237263 random_forest.cc:290] Training random forest on 67349 example(s) and 512 feature(s).\n",
            "I0430 10:30:37.062117 1274213 random_forest.cc:559] Training of tree  1/100 (tree index:1) done accuracy:0.725875 logloss:9.88048\n",
            "I0430 10:30:40.057393 1274209 random_forest.cc:559] Training of tree  11/100 (tree index:9) done accuracy:0.791226 logloss:1.9747\n",
            "I0430 10:30:44.680320 1274212 random_forest.cc:559] Training of tree  21/100 (tree index:21) done accuracy:0.82676 logloss:0.704178\n",
            "I0430 10:30:48.636935 1274213 random_forest.cc:559] Training of tree  31/100 (tree index:30) done accuracy:0.843086 logloss:0.494832\n",
            "I0430 10:30:51.570978 1274212 random_forest.cc:559] Training of tree  41/100 (tree index:40) done accuracy:0.852336 logloss:0.415244\n",
            "I0430 10:30:55.654403 1274214 random_forest.cc:559] Training of tree  51/100 (tree index:50) done accuracy:0.856627 logloss:0.389767\n",
            "I0430 10:31:01.540452 1274213 random_forest.cc:559] Training of tree  61/100 (tree index:60) done accuracy:0.860339 logloss:0.378651\n",
            "I0430 10:31:07.810440 1274209 random_forest.cc:559] Training of tree  71/100 (tree index:70) done accuracy:0.862908 logloss:0.37029\n",
            "I0430 10:31:14.442523 1274212 random_forest.cc:559] Training of tree  81/100 (tree index:82) done accuracy:0.864155 logloss:0.364619\n",
            "I0430 10:31:18.243710 1274210 random_forest.cc:559] Training of tree  91/100 (tree index:90) done accuracy:0.866011 logloss:0.362683\n",
            "I0430 10:31:22.254260 1274212 random_forest.cc:559] Training of tree  100/100 (tree index:99) done accuracy:0.86613 logloss:0.360695\n",
            "I0430 10:31:22.254475 1237263 random_forest.cc:626] Final OOB metrics: accuracy:0.86613 logloss:0.360695\n",
            "I0430 10:31:22.597651 1237263 kernel.cc:794] Export model in log directory: /tmp/tmpuf2jtxrh\n",
            "I0430 10:31:24.031691 1237263 kernel.cc:802] Save model in resources\n",
            "I0430 10:31:26.755865 1237263 kernel.cc:919] Loading model from path\n",
            "I0430 10:31:27.905046 1237263 decision_forest.cc:585] Model loaded with 100 root(s), 557956 node(s), and 512 input feature(s).\n",
            "I0430 10:31:27.905649 1237263 abstract_model.cc:861] Engine \"RandomForestGeneric\" built\n",
            "I0430 10:31:27.905836 1237263 kernel.cc:787] Use fast generic engine\n"
          ]
        }
      ],
      "source": [
        "%output_height 300px\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "embedding = hub.KerasLayer(\"http://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "# NNLM (https://tfhub.dev/google/nnlm-en-dim128/2) is also a good choice.\n",
        "# embedding = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
        "\n",
        "sentence = tf.keras.layers.Input(shape=(), name=\"sentence\", dtype=tf.string)\n",
        "embedded_sentence = embedding(sentence)\n",
        "\n",
        "raw_inputs = {\"sentence\": sentence}\n",
        "processed_inputs = {\"embedded_sentence\": embedded_sentence}\n",
        "preprocessor = tf.keras.Model(inputs=raw_inputs, outputs=processed_inputs)\n",
        "\n",
        "model_2 = tfdf.keras.RandomForestModel(\n",
        "    preprocessing=preprocessor,\n",
        "    num_trees=100)\n",
        "model_2.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "with sys_pipes():\n",
        "  model_2.fit(x=train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "executionInfo": {
          "elapsed": 2563,
          "status": "ok",
          "timestamp": 1619771494740,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "xPLoDqiFKY18",
        "outputId": "bf4a5ef3-7df7-4d91-9534-23ea4eac6017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 2s 14ms/step - loss: 0.0000e+00 - accuracy: 0.7672\n",
            "BinaryCrossentropyloss: 0.0\n",
            "Accuracy: 0.767201840877533\n"
          ]
        }
      ],
      "source": [
        "evaluation = model_2.evaluate(test_ds)\n",
        "\n",
        "print(f\"BinaryCrossentropyloss: {evaluation[0]}\")\n",
        "print(f\"Accuracy: {evaluation[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPsD3LyaMLHm"
      },
      "source": [
        "Note that categorical sets represent text differently from a dense embedding, so it may be useful to use both strategies jointly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJIxGwwzMkFl"
      },
      "source": [
        "## Train a Gradient Boosted Decision Trees (GBDT) and a Neural Network together\n",
        "\n",
        "In the previous example, we used a pre-trained Neural Network (NN) to \n",
        "process the text features before passing them to the Random Forest. In this example, we will train both the Neural Network and the Random Forest from scratch.\n",
        "\n",
        "TF-DF's Decision Forests do not back-propagate gradients ([although this is the subject of ongoing research](https://arxiv.org/abs/2007.14761)). Therefore, the training happens in two stages:\n",
        "\n",
        "1. Train the neural-network as a standard classification task:\n",
        "\n",
        "```\n",
        "example â†’ [Normalize] â†’ [Neural Network*] â†’ [classification head] â†’ prediction\n",
        "*: Training.\n",
        "```\n",
        "\n",
        "2. Replace the Neural Network's head (the last layer and the soft-max) with a Random Forest. Train the Random Forest as usual:\n",
        "\n",
        "```\n",
        "example â†’ [Normalize] â†’ [Neural Network] â†’ [Random Forest*] â†’ prediction\n",
        "*: Training.\n",
        "```\n",
        "\n",
        "We will use the [Palmer's Penguins](https://allisonhorst.github.io/palmerpenguins/articles/intro.html) dataset already used in the Beginner colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "height": 142
        },
        "executionInfo": {
          "elapsed": 440,
          "status": "ok",
          "timestamp": 1619771495187,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "9lA3peQ4sa9a",
        "outputId": "448a14e4-e86f-42ec-ff02-1149c49d77aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\u003cdiv\u003e\n",
              "\u003cstyle scoped\u003e\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\u003c/style\u003e\n",
              "\u003ctable border=\"1\" class=\"dataframe\"\u003e\n",
              "  \u003cthead\u003e\n",
              "    \u003ctr style=\"text-align: right;\"\u003e\n",
              "      \u003cth\u003e\u003c/th\u003e\n",
              "      \u003cth\u003especies\u003c/th\u003e\n",
              "      \u003cth\u003eisland\u003c/th\u003e\n",
              "      \u003cth\u003ebill_length_mm\u003c/th\u003e\n",
              "      \u003cth\u003ebill_depth_mm\u003c/th\u003e\n",
              "      \u003cth\u003eflipper_length_mm\u003c/th\u003e\n",
              "      \u003cth\u003ebody_mass_g\u003c/th\u003e\n",
              "      \u003cth\u003esex\u003c/th\u003e\n",
              "      \u003cth\u003eyear\u003c/th\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/thead\u003e\n",
              "  \u003ctbody\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e0\u003c/th\u003e\n",
              "      \u003ctd\u003eAdelie\u003c/td\u003e\n",
              "      \u003ctd\u003eTorgersen\u003c/td\u003e\n",
              "      \u003ctd\u003e39.1\u003c/td\u003e\n",
              "      \u003ctd\u003e18.7\u003c/td\u003e\n",
              "      \u003ctd\u003e181.0\u003c/td\u003e\n",
              "      \u003ctd\u003e3750.0\u003c/td\u003e\n",
              "      \u003ctd\u003emale\u003c/td\u003e\n",
              "      \u003ctd\u003e2007\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e1\u003c/th\u003e\n",
              "      \u003ctd\u003eAdelie\u003c/td\u003e\n",
              "      \u003ctd\u003eTorgersen\u003c/td\u003e\n",
              "      \u003ctd\u003e39.5\u003c/td\u003e\n",
              "      \u003ctd\u003e17.4\u003c/td\u003e\n",
              "      \u003ctd\u003e186.0\u003c/td\u003e\n",
              "      \u003ctd\u003e3800.0\u003c/td\u003e\n",
              "      \u003ctd\u003efemale\u003c/td\u003e\n",
              "      \u003ctd\u003e2007\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "    \u003ctr\u003e\n",
              "      \u003cth\u003e2\u003c/th\u003e\n",
              "      \u003ctd\u003eAdelie\u003c/td\u003e\n",
              "      \u003ctd\u003eTorgersen\u003c/td\u003e\n",
              "      \u003ctd\u003e40.3\u003c/td\u003e\n",
              "      \u003ctd\u003e18.0\u003c/td\u003e\n",
              "      \u003ctd\u003e195.0\u003c/td\u003e\n",
              "      \u003ctd\u003e3250.0\u003c/td\u003e\n",
              "      \u003ctd\u003efemale\u003c/td\u003e\n",
              "      \u003ctd\u003e2007\u003c/td\u003e\n",
              "    \u003c/tr\u003e\n",
              "  \u003c/tbody\u003e\n",
              "\u003c/table\u003e\n",
              "\u003c/div\u003e"
            ],
            "text/plain": [
              "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g     sex  year\n",
              "0  Adelie  Torgersen            39.1           18.7              181.0       3750.0    male  2007\n",
              "1  Adelie  Torgersen            39.5           17.4              186.0       3800.0  female  2007\n",
              "2  Adelie  Torgersen            40.3           18.0              195.0       3250.0  female  2007"
            ]
          },
          "execution_count": 30,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download the dataset\n",
        "!wget -q https://storage.googleapis.com/download.tensorflow.org/data/palmer_penguins/penguins.csv -O /tmp/penguins.csv\n",
        "\n",
        "# Load a dataset into a Pandas Dataframe.\n",
        "dataset_df = pd.read_csv(\"/tmp/penguins.csv\")\n",
        "\n",
        "# Display the first 3 examples.\n",
        "dataset_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "executionInfo": {
          "elapsed": 48,
          "status": "ok",
          "timestamp": 1619771495348,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "rtyi8UoqtzhM"
      },
      "outputs": [],
      "source": [
        "# Curate the dataset\n",
        "# See the beginner colab for explanations.\n",
        "\n",
        "label = \"species\"\n",
        "\n",
        "# Replaces numerical NaN (representing missing values in Pandas Dataframe) with 0s.\n",
        "# ...Neural Nets don't work well with numerical NaNs.\n",
        "for col in dataset_df.columns:\n",
        "  if dataset_df[col].dtype not in [str, object]:\n",
        "    dataset_df[col] = dataset_df[col].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "executionInfo": {
          "elapsed": 83,
          "status": "ok",
          "timestamp": 1619771495434,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "GKrW5Yfjso0k",
        "outputId": "bf558ec8-ff1c-40d5-eb87-cdd8d71973aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "248 examples in training, 96 examples for testing.\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into a training and testing dataset.\n",
        "\n",
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) \u003c test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(dataset_df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "# Convert the datasets into tensorflow datasets\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "executionInfo": {
          "elapsed": 343,
          "status": "ok",
          "timestamp": 1619771495786,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "KzocgbYNsH6y"
      },
      "outputs": [],
      "source": [
        "# Let's create a neural network.\n",
        "\n",
        "# The inputs\n",
        "input_1 = tf.keras.Input(shape=(1,), name=\"bill_length_mm\", dtype=\"float\")\n",
        "input_2 = tf.keras.Input(shape=(1,), name=\"island\", dtype=\"string\")\n",
        "\n",
        "# For simplicity, we only inject and prepare two input features.\n",
        "\n",
        "nn_raw_inputs = [input_1, input_2]\n",
        "\n",
        "# Normalization.\n",
        "Normalization = tf.keras.layers.experimental.preprocessing.Normalization\n",
        "CategoryEncoding = tf.keras.layers.experimental.preprocessing.CategoryEncoding\n",
        "StringLookup = tf.keras.layers.experimental.preprocessing.StringLookup\n",
        "\n",
        "values = train_ds_pd[\"bill_length_mm\"].values\n",
        "input_1_normalizer = Normalization()\n",
        "input_1_normalizer.adapt(values)\n",
        "\n",
        "values = train_ds_pd[\"island\"].values\n",
        "input_2_indexer = StringLookup(max_tokens=32)\n",
        "input_2_indexer.adapt(values)\n",
        "\n",
        "input_2_onehot = CategoryEncoding(output_mode=\"binary\", max_tokens=32)\n",
        "\n",
        "normalized_input_1 = input_1_normalizer(input_1)\n",
        "normalized_input_2 = input_2_onehot(input_2_indexer(input_2))\n",
        "\n",
        "nn_processed_inputs = [normalized_input_1, normalized_input_2]\n",
        "\n",
        "# Neural network\n",
        "y = tf.keras.layers.Concatenate()(nn_processed_inputs)\n",
        "y = tf.keras.layers.Dense(16, activation=tf.nn.relu6)(y)\n",
        "y = tf.keras.layers.Dense(8, activation=tf.nn.relu, name=\"last\")(y)\n",
        "y = tf.keras.layers.Dense(3)(y)\n",
        "# \"3\" for the three label classes. If we have a binary classification, the\n",
        "# output dim would be 1.\n",
        "\n",
        "nn_model = tf.keras.models.Model(nn_raw_inputs, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "executionInfo": {
          "elapsed": 66,
          "status": "ok",
          "timestamp": 1619771495855,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "7fnpGNyTuXvH"
      },
      "outputs": [],
      "source": [
        "# Let's add a Random Forest on top of the neural network.\n",
        "\n",
        "# Get the last hidden layer of the neural net. This is what the decision forest\n",
        "# will \"see\".\n",
        "nn_head = nn_model.get_layer(\"last\").output\n",
        "\n",
        "# To reduce the risk of mistakes, we group both the decision forest and the\n",
        "# neural network in a single keras model.\n",
        "nn_without_head = tf.keras.models.Model(inputs=nn_model.inputs, outputs=nn_head)\n",
        "df_and_nn_model = tfdf.keras.RandomForestModel(preprocessing=nn_without_head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trq07lvMudlz"
      },
      "source": [
        "The model will be trained in two stages: First the neural network with its own head. Then, the random forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "height": 300
        },
        "executionInfo": {
          "elapsed": 1236,
          "status": "ok",
          "timestamp": 1619771497094,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "h4OyUWKiupuF",
        "outputId": "96ae18e1-4b71-4d5b-9256-8504a24676db"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "window[\"79cc79a4-a98e-11eb-b881-1ca0b880083b\"] = colab.output.setOutputHeight(\"300px\", false, {\"interactive\": true});\n",
              "//# sourceURL=js_483cbad79b"
            ],
            "text/plain": [
              "\u003cIPython.core.display.Javascript at 0x7f53b06986a0\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 75ms/step - loss: 1.1346 - accuracy: 0.2419 - val_loss: 1.1251 - val_accuracy: 0.2604\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1246 - accuracy: 0.2661 - val_loss: 1.1177 - val_accuracy: 0.2812\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.1166 - accuracy: 0.2782 - val_loss: 1.1103 - val_accuracy: 0.2917\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.1088 - accuracy: 0.2903 - val_loss: 1.1029 - val_accuracy: 0.2917\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.1011 - accuracy: 0.2944 - val_loss: 1.0955 - val_accuracy: 0.2917\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0937 - accuracy: 0.2944 - val_loss: 1.0885 - val_accuracy: 0.2917\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0865 - accuracy: 0.3105 - val_loss: 1.0818 - val_accuracy: 0.2917\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.0794 - accuracy: 0.3306 - val_loss: 1.0754 - val_accuracy: 0.3125\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.0726 - accuracy: 0.3750 - val_loss: 1.0689 - val_accuracy: 0.4062\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0658 - accuracy: 0.4194 - val_loss: 1.0622 - val_accuracy: 0.5312\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "island (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bill_length_mm (InputLayer)     [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "string_lookup_2 (StringLookup)  (None, 1)            0           island[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "normalization_2 (Normalization) (None, 1)            3           bill_length_mm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "category_encoding_2 (CategoryEn (None, 32)           0           string_lookup_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 33)           0           normalization_2[0][0]            \n",
            "                                                                 category_encoding_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 16)           544         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "last (Dense)                    (None, 8)            136         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 3)            27          last[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 710\n",
            "Trainable params: 707\n",
            "Non-trainable params: 3\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/google/_bazel_gbm/957f7e5526d4a3fbdb4405b22c6b2d1e/execroot/google3/bazel-out/k8-opt/bin/third_party/tensorflow_decision_forests/notebook.runfiles/google3/third_party/tensorflow/python/keras/engine/functional.py:591: UserWarning: Input dict contained keys ['bill_depth_mm', 'flipper_length_mm', 'body_mass_g', 'sex', 'year'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ]
        }
      ],
      "source": [
        "%output_height 300px\n",
        "# Train the neural network.\n",
        "\n",
        "nn_model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(),\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=[\"accuracy\"])\n",
        "\n",
        "nn_model.fit(x=train_ds, validation_data=test_ds, epochs=10)\n",
        "nn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "height": 300
        },
        "executionInfo": {
          "elapsed": 2155,
          "status": "ok",
          "timestamp": 1619771499253,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "JAc9niXqud7V",
        "outputId": "d8eabafc-827a-4c71-d9e0-d43adf6fbb07"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "window[\"7a8717b4-a98e-11eb-81e9-1ca0b880083b\"] = colab.output.setOutputHeight(\"300px\", false, {\"interactive\": true});\n",
              "//# sourceURL=js_16a39e20b8"
            ],
            "text/plain": [
              "\u003cIPython.core.display.Javascript at 0x7f53adca0e10\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I0430 10:31:37.628148 1237263 api.py:447] Collect training examples.\n",
            "Features: {'island': \u003ctf.Tensor 'data_4:0' shape=(None,) dtype=string\u003e, 'bill_length_mm': \u003ctf.Tensor 'data_1:0' shape=(None,) dtype=float64\u003e, 'bill_depth_mm': \u003ctf.Tensor 'data:0' shape=(None,) dtype=float64\u003e, 'flipper_length_mm': \u003ctf.Tensor 'data_3:0' shape=(None,) dtype=float64\u003e, 'body_mass_g': \u003ctf.Tensor 'data_2:0' shape=(None,) dtype=float64\u003e, 'sex': \u003ctf.Tensor 'data_5:0' shape=(None,) dtype=string\u003e, 'year': \u003ctf.Tensor 'data_6:0' shape=(None,) dtype=int64\u003e}\n",
            "Label: Tensor(\"data_7:0\", shape=(None,), dtype=int64)\n",
            "I0430 10:31:37.681892 1237263 api.py:447] Applying preprocessing on inputs. Result: Tensor(\"model_4/last/Relu:0\", shape=(None, 8), dtype=float32)\n",
            "I0430 10:31:37.734096 1237263 api.py:447] Normalized features: {'model_4/last/Relu:0.0': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice:0' shape=(None,) dtype=float32\u003e), 'model_4/last/Relu:0.1': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_1:0' shape=(None,) dtype=float32\u003e), 'model_4/last/Relu:0.2': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_2:0' shape=(None,) dtype=float32\u003e), 'model_4/last/Relu:0.3': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_3:0' shape=(None,) dtype=float32\u003e), 'model_4/last/Relu:0.4': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_4:0' shape=(None,) dtype=float32\u003e), 'model_4/last/Relu:0.5': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_5:0' shape=(None,) dtype=float32\u003e), 'model_4/last/Relu:0.6': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_6:0' shape=(None,) dtype=float32\u003e), 'model_4/last/Relu:0.7': SemanticTensor(semantic=\u003cSemantic.NUMERICAL: 1\u003e, tensor=\u003ctf.Tensor 'strided_slice_7:0' shape=(None,) dtype=float32\u003e)}\n",
            "4/4 [==============================] - 1s 2ms/step\n",
            "I0430 10:31:37.805054 1237263 kernel.cc:712] Start Yggdrasil model training\n",
            "I0430 10:31:37.805124 1237263 kernel.cc:713] Collect training examples\n",
            "I0430 10:31:37.805169 1237263 kernel.cc:374] Number of batches: 4\n",
            "I0430 10:31:37.805190 1237263 kernel.cc:375] Number of examples: 248\n",
            "I0430 10:31:37.805238 1237263 kernel.cc:735] Dataset:\n",
            "Number of records: 248\n",
            "Number of columns: 9\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 8 (88.8889%)\n",
            "\tCATEGORICAL: 1 (11.1111%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 8 (88.8889%)\n",
            "\t0: \"model_4/last/Relu:0.0\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
            "\t1: \"model_4/last/Relu:0.1\" NUMERICAL mean:0.0499804 min:0 max:0.47628 sd:0.0941901\n",
            "\t2: \"model_4/last/Relu:0.2\" NUMERICAL mean:0.06965 min:0 max:0.216886 sd:0.0657421\n",
            "\t3: \"model_4/last/Relu:0.3\" NUMERICAL mean:0.119603 min:0 max:0.596125 sd:0.109506\n",
            "\t4: \"model_4/last/Relu:0.4\" NUMERICAL mean:0.0208096 min:0 max:0.505657 sd:0.0587136\n",
            "\t5: \"model_4/last/Relu:0.5\" NUMERICAL mean:0.0473954 min:0 max:0.209647 sd:0.0657324\n",
            "\t6: \"model_4/last/Relu:0.6\" NUMERICAL mean:0.0497947 min:0 max:0.361855 sd:0.0693313\n",
            "\t7: \"model_4/last/Relu:0.7\" NUMERICAL mean:0.0499195 min:0 max:0.333026 sd:0.0876104\n",
            "\n",
            "CATEGORICAL: 1 (11.1111%)\n",
            "\t8: \"__LABEL\" CATEGORICAL integerized vocab-size:4 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "I0430 10:31:37.805299 1237263 kernel.cc:738] Configure learner\n",
            "I0430 10:31:37.805391 1237263 kernel.cc:763] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"model_4/last/Relu:0\\\\.0\"\n",
            "features: \"model_4/last/Relu:0\\\\.1\"\n",
            "features: \"model_4/last/Relu:0\\\\.2\"\n",
            "features: \"model_4/last/Relu:0\\\\.3\"\n",
            "features: \"model_4/last/Relu:0\\\\.4\"\n",
            "features: \"model_4/last/Relu:0\\\\.5\"\n",
            "features: \"model_4/last/Relu:0\\\\.6\"\n",
            "features: \"model_4/last/Relu:0\\\\.7\"\n",
            "label: \"__LABEL\"\n",
            "task: CLASSIFICATION\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 300\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: false\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    num_candidate_attributes_ratio: -1\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "}\n",
            "I0430 10:31:37.805492 1237263 kernel.cc:766] Deployment config:\n",
            "I0430 10:31:37.805503 1237263 kernel.cc:788] Train model\n",
            "I0430 10:31:37.805543 1237263 random_forest.cc:290] Training random forest on 248 example(s) and 8 feature(s).\n",
            "I0430 10:31:38.144348 1282294 random_forest.cc:559] Training of tree  1/300 (tree index:4) done accuracy:0.935484 logloss:2.3254\n",
            "I0430 10:31:38.145358 1282297 random_forest.cc:559] Training of tree  11/300 (tree index:13) done accuracy:0.955466 logloss:0.775272\n",
            "I0430 10:31:38.146263 1282294 random_forest.cc:559] Training of tree  21/300 (tree index:22) done accuracy:0.959677 logloss:0.770536\n",
            "I0430 10:31:38.147119 1282297 random_forest.cc:559] Training of tree  31/300 (tree index:30) done accuracy:0.955645 logloss:0.632773\n",
            "I0430 10:31:38.148377 1282293 random_forest.cc:559] Training of tree  41/300 (tree index:37) done accuracy:0.959677 logloss:0.496755\n",
            "I0430 10:31:38.149097 1282296 random_forest.cc:559] Training of tree  51/300 (tree index:52) done accuracy:0.967742 logloss:0.498373\n",
            "I0430 10:31:38.149738 1282296 random_forest.cc:559] Training of tree  61/300 (tree index:63) done accuracy:0.96371 logloss:0.502118\n",
            "I0430 10:31:38.150306 1282295 random_forest.cc:559] Training of tree  71/300 (tree index:68) done accuracy:0.96371 logloss:0.504225\n",
            "I0430 10:31:38.151046 1282296 random_forest.cc:559] Training of tree  81/300 (tree index:81) done accuracy:0.96371 logloss:0.505688\n",
            "I0430 10:31:38.151905 1282297 random_forest.cc:559] Training of tree  91/300 (tree index:90) done accuracy:0.96371 logloss:0.504188\n",
            "I0430 10:31:38.153536 1282297 random_forest.cc:559] Training of tree  102/300 (tree index:101) done accuracy:0.967742 logloss:0.50491\n",
            "I0430 10:31:38.155400 1282297 random_forest.cc:559] Training of tree  112/300 (tree index:111) done accuracy:0.967742 logloss:0.50548\n",
            "I0430 10:31:38.156781 1282293 random_forest.cc:559] Training of tree  122/300 (tree index:122) done accuracy:0.967742 logloss:0.507286\n",
            "I0430 10:31:38.159290 1282293 random_forest.cc:559] Training of tree  132/300 (tree index:131) done accuracy:0.967742 logloss:0.506375\n",
            "I0430 10:31:38.162111 1282293 random_forest.cc:559] Training of tree  142/300 (tree index:141) done accuracy:0.967742 logloss:0.506481\n",
            "I0430 10:31:38.165234 1282293 random_forest.cc:559] Training of tree  152/300 (tree index:151) done accuracy:0.967742 logloss:0.506983\n",
            "I0430 10:31:38.167348 1282296 random_forest.cc:559] Training of tree  162/300 (tree index:160) done accuracy:0.967742 logloss:0.50866\n",
            "I0430 10:31:38.168102 1282297 random_forest.cc:559] Training of tree  172/300 (tree index:170) done accuracy:0.967742 logloss:0.509616\n",
            "I0430 10:31:38.169127 1282297 random_forest.cc:559] Training of tree  182/300 (tree index:181) done accuracy:0.967742 logloss:0.509696\n",
            "I0430 10:31:38.170705 1282297 random_forest.cc:559] Training of tree  192/300 (tree index:191) done accuracy:0.967742 logloss:0.508842\n",
            "I0430 10:31:38.172255 1282297 random_forest.cc:559] Training of tree  202/300 (tree index:201) done accuracy:0.967742 logloss:0.509772\n",
            "I0430 10:31:38.173345 1282294 random_forest.cc:559] Training of tree  212/300 (tree index:211) done accuracy:0.967742 logloss:0.510207\n",
            "I0430 10:31:38.174867 1282294 random_forest.cc:559] Training of tree  222/300 (tree index:221) done accuracy:0.967742 logloss:0.510941\n",
            "I0430 10:31:38.177770 1282293 random_forest.cc:559] Training of tree  232/300 (tree index:232) done accuracy:0.967742 logloss:0.511564\n",
            "I0430 10:31:38.178283 1282293 random_forest.cc:559] Training of tree  242/300 (tree index:241) done accuracy:0.967742 logloss:0.511666\n",
            "I0430 10:31:38.178723 1282298 random_forest.cc:559] Training of tree  252/300 (tree index:252) done accuracy:0.967742 logloss:0.511738\n",
            "I0430 10:31:38.179285 1282295 random_forest.cc:559] Training of tree  262/300 (tree index:259) done accuracy:0.967742 logloss:0.5112\n",
            "I0430 10:31:38.179715 1282293 random_forest.cc:559] Training of tree  272/300 (tree index:269) done accuracy:0.967742 logloss:0.384204\n",
            "I0430 10:31:38.180157 1282296 random_forest.cc:559] Training of tree  282/300 (tree index:283) done accuracy:0.967742 logloss:0.384055\n",
            "I0430 10:31:38.180653 1282296 random_forest.cc:559] Training of tree  292/300 (tree index:291) done accuracy:0.967742 logloss:0.384289\n",
            "I0430 10:31:38.181050 1282296 random_forest.cc:559] Training of tree  300/300 (tree index:297) done accuracy:0.967742 logloss:0.384092\n",
            "I0430 10:31:38.181125 1237263 random_forest.cc:626] Final OOB metrics: accuracy:0.967742 logloss:0.384092\n",
            "I0430 10:31:38.524892 1237263 kernel.cc:794] Export model in log directory: /tmp/tmp150l_b1g\n",
            "I0430 10:31:38.541070 1237263 kernel.cc:802] Save model in resources\n",
            "I0430 10:31:38.549931 1237263 kernel.cc:919] Loading model from path\n",
            "I0430 10:31:38.555452 1237263 decision_forest.cc:585] Model loaded with 300 root(s), 5228 node(s), and 7 input feature(s).\n",
            "I0430 10:31:38.555666 1237263 abstract_model.cc:861] Engine \"RandomForestGeneric\" built\n",
            "I0430 10:31:38.555725 1237263 kernel.cc:787] Use fast generic engine\n",
            "W0430 10:31:39.202565 1237263 def_function.py:160] 5 out of the last 5 calls to \u003cfunction CoreModel.make_predict_function.\u003clocals\u003e.predict_function_trained at 0x7f53acabbd08\u003e triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ],
      "source": [
        "%output_height 300px\n",
        "# Train the random forest.\n",
        "\n",
        "df_and_nn_model.compile(metrics=[\"accuracy\"])\n",
        "with sys_pipes():\n",
        "  df_and_nn_model.fit(x=train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF8Ru2HSv1a5"
      },
      "source": [
        "We can now evaluate the composed model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "executionInfo": {
          "elapsed": 186,
          "status": "ok",
          "timestamp": 1619771499446,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "EPMlcObzuw89",
        "outputId": "216f7334-6f3d-4c65-cab4-7952d297ce29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.9583\n",
            "Evaluation: [0.0, 0.9583333134651184]\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluation:\", df_and_nn_model.evaluate(test_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awiHEznlv5sI"
      },
      "source": [
        "and compare it to the Neural Network alone:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "executionInfo": {
          "elapsed": 107,
          "status": "ok",
          "timestamp": 1619771499563,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "--ompWYTvxM-",
        "outputId": "867e4b9b-1c09-47fc-e5a6-fce54e3aea41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 2ms/step - loss: 1.0622 - accuracy: 0.5312\n",
            "Evaluation : [1.0621919631958008, 0.53125]\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluation :\", nn_model.evaluate(test_ds))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "Intermediate colab | TensorFlow Decision Forests",
      "provenance": [
        {
          "file_id": "1L61CtsZzgRs09yoj-Bac3o6eUeFGe-qe",
          "timestamp": 1617976681796
        },
        {
          "file_id": "/piper/depot/google3/third_party/tensorflow_decision_forests/documentation/intermediate_colab.ipynb?workspaceId=gbm:sml_oss_colabs::citc",
          "timestamp": 1617882306082
        },
        {
          "file_id": "19bVQTYDbGlobMBky5JK8iK1CoAxdKErm",
          "timestamp": 1617202340185
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
